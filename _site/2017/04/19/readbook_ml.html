<h1 id="机器学习周志华一">《机器学习》周志华（一）</h1>
<p>#阅读与写作</p>
<h3 id="机器学习的定义">机器学习的定义</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>对于一件需要干的事 ，根据某些经验和一些学习算法。产生一些模型机器学习是一门研究“学习算法”的学问。
</code></pre>
</div>

<h3 id="一些术语">一些术语</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>* 对于**数据集**（经验：需要从中获得信息）。我们把各方面的信息看成数据的**属性**。属性的多少看成一个数据的**维度**。并把一个数据看成一个**样本**
* 把预测离散值的问题叫做**分类**，把预测连续值的问题看作是**回归**。
* 	把有标记信息的看成是有监督学习，把没有标记的看做无监督学习
	1. ex:如回归和分类都是典型监督学习，聚类为无监督学习
	2. 比如有答案的学习为监督学习，没答案的学习则为无监督学习
* 泛化能力为预测整个样本的能力，只在训练集效果好，在测试集效果不好，可以理解为过拟合。
</code></pre>
</div>

<h3 id="预测一个西瓜是不是好瓜的例子">预测一个西瓜是不是好瓜的例子</h3>
<p>引出归纳偏好的例子：对于很多可以选择划分的样本属性，如何选择归纳偏好，选择什么样的学习模型就显得十分重要。
比如一个好瓜到底是色泽更重要还是声音重要，都会使得最后的预测结果不同。</p>

<h3 id="nfl定理">NFL定理</h3>
<p>no free lunch对于一个泛化的问题。那么学习期望的算法都是一样的。
证明？？
但是对于我们拿来讨论的问题来说不会出现这种情况。因为我们都是讨论一些具体的问题
所以这个定理告诉我们对于机器学习要做到具体问题具体分析。</p>

